{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ddf451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb4c8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of images in the directory: 319\n",
      "['CheMed123_10.jpg', 'CheMed123_11.jpg', 'CheMed123_13.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Use YOLOv8n for faster CPU-based inference\n",
    "model = YOLO('yolov8l.pt')\n",
    "\n",
    "# Directory containing test images``\n",
    "image_dir = \"../data/raw/telegram_media\"\n",
    "\n",
    "# Images to test â€” pick 3 to 5 samples\n",
    "image_samples = [f for f in os.listdir(image_dir) if f.lower().endswith(\".jpg\")]\n",
    "print(f\"The total number of images in the directory: {len(image_samples)}\")\n",
    "\n",
    "# Code to check if the directory is empty\n",
    "if not image_samples:\n",
    "    print(f\"no images in the directory: {image_dir}\")\n",
    "\n",
    "# Output directory for saving bounding box images\n",
    "output_dir = \"../data/processed/annotated\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(image_samples[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc7eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18372.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18372.jpg: 640x448 1 bottle, 1573.1ms\n",
      "Speed: 44.8ms preprocess, 1573.1ms inference, 29.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18372.jpg\n",
      "Detections:\n",
      "Detected bottle with confidence score of  0.87\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18373.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18373.jpg: 640x640 1 cell phone, 2420.4ms\n",
      "Speed: 11.9ms preprocess, 2420.4ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18373.jpg\n",
      "Detections:\n",
      "Detected cell phone with confidence score of  0.27\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18374.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18374.jpg: 480x640 (no detections), 1569.1ms\n",
      "Speed: 6.0ms preprocess, 1569.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18374.jpg\n",
      "Detections:\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18375.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18375.jpg: 640x640 1 cup, 1735.8ms\n",
      "Speed: 7.9ms preprocess, 1735.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18375.jpg\n",
      "Detections:\n",
      "Detected cup with confidence score of  0.70\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18376.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18376.jpg: 640x640 1 cup, 1 cell phone, 1932.9ms\n",
      "Speed: 7.3ms preprocess, 1932.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18376.jpg\n",
      "Detections:\n",
      "Detected cup with confidence score of  0.89\n",
      "Detected cell phone with confidence score of  0.28\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18377.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18377.jpg: 640x640 1 cell phone, 1879.6ms\n",
      "Speed: 10.0ms preprocess, 1879.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18377.jpg\n",
      "Detections:\n",
      "Detected cell phone with confidence score of  0.66\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18378.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18378.jpg: 640x448 1 parking meter, 1511.0ms\n",
      "Speed: 15.1ms preprocess, 1511.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18378.jpg\n",
      "Detections:\n",
      "Detected parking meter with confidence score of  0.36\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18379.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18379.jpg: 640x640 (no detections), 2227.0ms\n",
      "Speed: 4.4ms preprocess, 2227.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18379.jpg\n",
      "Detections:\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18381.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18381.jpg: 640x608 2 persons, 1904.2ms\n",
      "Speed: 7.4ms preprocess, 1904.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 608)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18381.jpg\n",
      "Detections:\n",
      "Detected person with confidence score of  0.73\n",
      "Detected person with confidence score of  0.71\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18382.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18382.jpg: 640x640 1 cup, 2237.2ms\n",
      "Speed: 7.7ms preprocess, 2237.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18382.jpg\n",
      "Detections:\n",
      "Detected cup with confidence score of  0.43\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18383.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18383.jpg: 640x480 1 person, 2247.3ms\n",
      "Speed: 5.5ms preprocess, 2247.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18383.jpg\n",
      "Detections:\n",
      "Detected person with confidence score of  0.29\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18384.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18384.jpg: 640x480 (no detections), 1357.1ms\n",
      "Speed: 9.7ms preprocess, 1357.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18384.jpg\n",
      "Detections:\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18385.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18385.jpg: 640x640 1 refrigerator, 1669.6ms\n",
      "Speed: 10.0ms preprocess, 1669.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18385.jpg\n",
      "Detections:\n",
      "Detected refrigerator with confidence score of  0.88\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18386.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18386.jpg: 640x384 1 bottle, 1 dining table, 1383.9ms\n",
      "Speed: 4.0ms preprocess, 1383.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18386.jpg\n",
      "Detections:\n",
      "Detected bottle with confidence score of  0.99\n",
      "Detected dining table with confidence score of  0.66\n",
      "Processing image in ../data/raw/telegram_media\\lobelia4cosmetics_18387.jpg...\n",
      "\n",
      "image 1/1 c:\\Users\\adoni\\Desktop\\KAIM COURSE\\WEEK-7\\ShippingDataProduct\\notebooks\\..\\data\\raw\\telegram_media\\lobelia4cosmetics_18387.jpg: 640x640 (no detections), 1819.5ms\n",
      "Speed: 7.3ms preprocess, 1819.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "saved Detaection result in ../data/processed/annotated\\processed_lobelia4cosmetics_18387.jpg\n",
      "Detections:\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"bottle\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.8728799819946289\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cell phone\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.2718942165374756\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [],\n",
      "  \"confs\": []\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cup\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.7035598158836365\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cup\",\n",
      "    \"cell phone\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.8914657235145569,\n",
      "    0.28258055448532104\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cell phone\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.6581494212150574\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"parking meter\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.3605716824531555\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [],\n",
      "  \"confs\": []\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"person\",\n",
      "    \"person\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.7345675230026245,\n",
      "    0.7105132341384888\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cup\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.42976114153862\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"person\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.2894914150238037\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [],\n",
      "  \"confs\": []\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"refrigerator\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.8785775303840637\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"bottle\",\n",
      "    \"dining table\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.9870970249176025,\n",
      "    0.6606900095939636\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [],\n",
      "  \"confs\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "for filename in image_samples[105:120]:\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    print(f\"Processing image in {image_path}...\")\n",
    "\n",
    "    try:\n",
    "        # Run detection\n",
    "        results = model(image_path)\n",
    "        \n",
    "        for r in results:\n",
    "            imarray = r.plot()\n",
    "            save_filename = f\"processed_{filename}\"\n",
    "            save_path = os.path.join(output_dir, save_filename)\n",
    "            cv2.imwrite(save_path, imarray)\n",
    "\n",
    "            print(f\"saved Detaection result in {save_path}\")\n",
    "\n",
    "            print(\"Detections:\")\n",
    "            detections = {}\n",
    "            lables = []\n",
    "            confs = [] \n",
    "            for box in r.boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                label = model.names[cls]\n",
    "                lables.append(label)\n",
    "                confs.append(conf) \n",
    "                print(f\"Detected {label} with confidence score of  {conf:.2f}\")\n",
    "            # Load image detections in the form of a dictionsry \n",
    "            detections[\"labels\"]= lables\n",
    "            detections[\"confs\"]= confs\n",
    "            results_list.append(detections)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process image: {image_path} \\n {e}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46aeeaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"bottle\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.8728799819946289\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cell phone\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.2718942165374756\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [],\n",
      "  \"confs\": []\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cup\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.7035598158836365\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cup\",\n",
      "    \"cell phone\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.8914657235145569,\n",
      "    0.28258055448532104\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cell phone\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.6581494212150574\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"parking meter\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.3605716824531555\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [],\n",
      "  \"confs\": []\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"person\",\n",
      "    \"person\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.7345675230026245,\n",
      "    0.7105132341384888\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"cup\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.42976114153862\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"person\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.2894914150238037\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [],\n",
      "  \"confs\": []\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"refrigerator\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.8785775303840637\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [\n",
      "    \"bottle\",\n",
      "    \"dining table\"\n",
      "  ],\n",
      "  \"confs\": [\n",
      "    0.9870970249176025,\n",
      "    0.6606900095939636\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n",
      "{\n",
      "  \"labels\": [],\n",
      "  \"confs\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print each result as pretty JSON\n",
    "for item in results_list:\n",
    "    print(\"\\n\")\n",
    "    print(json.dumps(item, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b05e807",
   "metadata": {},
   "source": [
    "# This notebook demonstrates the example outputs and how the yolo insight extraction will work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
